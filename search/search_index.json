{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#tamedia-kubernetes-as-a-service-kaas-terraform-module-alpha","title":"Tamedia Kubernetes as a Service (KaaS) Terraform Module (Alpha)","text":"<p>Opinionated batteries included Terraform module to deploy Kubernetes in AWS. Includes:</p> <p>Core components (installed by default):</p> <ul> <li>EBS CSI Driver IRSA</li> <li>VPC CNI IRSA</li> <li>CoreDNS</li> <li>Karpenter</li> <li>Metrics Server</li> <li>AWS Load Balancer Controller</li> <li>External DNS</li> <li>External Secrets</li> <li>Prometheus Operator</li> <li>Grafana</li> <li>Fluent Operator</li> <li>Fluentbit for Fargate</li> </ul> <p>Additional components (optional):</p> <ul> <li>Cert Manager</li> <li>Ingress Nginx</li> <li>Downscaler</li> </ul> <p>Integrations (optional):</p> <ul> <li>Okta</li> <li> <p>PagerDuty</p> </li> <li> <p>Log pods output with <code>var.logging_annotation</code> annotation to CloudWatch</p> </li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>The module needs some resources to be deployed in order to operate correctly:</p> <ul> <li>IAM Service-linked roles (<code>AWSServiceRoleForEC2Spot</code> and <code>AWSServiceRoleForEC2SpotFleet</code>) - docs</li> </ul>"},{"location":"#usage","title":"Usage","text":"<pre><code>module \"k8s_platform\" {\n  source = \"tx-pts-dai/kubernetes-platform/aws\"\n  # Pin this module to a specific version to avoid breaking changes\n  # version = \"0.0.0\"\n\n  name = \"example-platform\"\n\n  vpc = {\n    enabled = true\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n  }\n}\n</code></pre> <p>See the Examples below for more use cases</p>"},{"location":"#explanation-and-description-of-interesting-use-cases","title":"Explanation and description of interesting use-cases","text":"<p>Why this module?</p> <ul> <li>To provide an AWS account with a K8s cluster with batteries included so that you can start deploying your workloads on a well-built foundation</li> <li>To encourage standardization and common practices</li> <li>To ease maintenance</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Complete - Includes creation of VPC, k8s cluster, addons and all the optional features.</li> <li>Simple - Simplest EKS deployment with default VPC, addons, ... creation</li> <li>Lacework - EKS deployment with Lacework integration</li> <li>Datadog - EKS deployment with Datadog Operator integration</li> </ul>"},{"location":"#cleanup-example-deployments","title":"Cleanup example deployments","text":"<p>Destroy Workflow - This manual workflow destroys deployed example deployments by selection the branch and the example to destroy.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>&lt; issues and contribution guidelines for public modules &gt;</p>"},{"location":"#pre-commit","title":"Pre-Commit","text":"<p>Installation: install pre-commit and execute <code>pre-commit install</code>. This will generate pre-commit hooks according to the config in <code>.pre-commit-config.yaml</code></p> <p>Before submitting a PR be sure to have used the pre-commit hooks or run: <code>pre-commit run -a</code></p> <p>The <code>pre-commit</code> command will run:</p> <ul> <li>Terraform fmt</li> <li>Terraform validate</li> <li>Terraform docs</li> <li>Terraform validate with tflint</li> <li>check for merge conflicts</li> <li>fix end of files</li> </ul> <p>as described in the <code>.pre-commit-config.yaml</code> file</p>"},{"location":"#requirements_1","title":"Requirements","text":"Name Version terraform &gt;= 1.6.0 aws &gt;= 5.42.0 helm &gt;= 2.12 kubectl &gt;= 2.0.2 kubernetes &gt;= 2.27 time &gt;= 0.11"},{"location":"#providers","title":"Providers","text":"Name Version aws &gt;= 5.42.0 time &gt;= 0.11"},{"location":"#modules","title":"Modules","text":"Name Source Version acm terraform-aws-modules/acm/aws 5.0.1 addons aws-ia/eks-blueprints-addons/aws 1.16.3 downscaler tx-pts-dai/downscaler/kubernetes 0.3.1 ebs_csi_driver_irsa terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks 5.44.0 eks terraform-aws-modules/eks/aws 20.23.0 fluent_operator ./modules/addon n/a grafana ./modules/addon n/a karpenter terraform-aws-modules/eks/aws//modules/karpenter 20.20.0 karpenter_crds ./modules/addon n/a karpenter_release ./modules/addon n/a karpenter_security_group ./modules/security-group n/a network ./modules/network n/a okta_secrets ./modules/addon n/a pagerduty_secrets ./modules/addon n/a prometheus_operator_crds ./modules/addon n/a prometheus_stack ./modules/addon n/a ssm ./modules/ssm n/a vpc_cni_irsa terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks 5.44.0"},{"location":"#resources","title":"Resources","text":"Name Type aws_cloudwatch_log_group.fluentbit resource aws_iam_policy.fluentbit resource aws_route_table_association.karpenter resource aws_security_group_rule.eks_control_plan_ingress resource aws_subnet.karpenter resource time_sleep.wait_on_destroy resource time_static.timestamp_id resource aws_availability_zones.available data source aws_iam_policy_document.fluentbit data source aws_iam_roles.iam_cluster_admins data source aws_iam_roles.sso data source aws_region.current data source aws_route53_zone.base_domain_zone data source aws_route_tables.private_route_tables data source"},{"location":"#inputs","title":"Inputs","text":"Name Description Type Default Required acm_certificate ACM certificate configuration. If wildcard_certificates is true, all domains will include a wildcard prefix. <pre>object({    domain_name               = optional(string) # Overrides base_domain    subject_alternative_names = optional(list(string), [])    wildcard_certificates     = optional(bool, false)    wait_for_validation       = optional(bool, false)  })</pre> <code>{}</code> no aws_load_balancer_controller AWS Load Balancer Controller configurations <code>any</code> <code>{}</code> no base_domain Base domain for the platform, used for ingress and ACM certificates <code>string</code> <code>\"test\"</code> no cert_manager Cert Manager configurations <code>any</code> <code>{}</code> no cluster_admins Map of IAM roles to add as cluster admins. Only exact matching role names are returned <pre>map(object({    role_name         = string    kubernetes_groups = optional(list(string))  }))</pre> <code>{}</code> no downscaler Downscaler configurations <code>any</code> <code>{}</code> no eks Map of EKS configurations <code>any</code> <code>{}</code> no enable_acm_certificate Enable ACM certificate <code>bool</code> <code>false</code> no enable_aws_load_balancer_controller Enable AWS Load Balancer Controller <code>bool</code> <code>true</code> no enable_cert_manager Enable Cert Manager <code>bool</code> <code>false</code> no enable_downscaler Enable Downscaler <code>bool</code> <code>false</code> no enable_external_dns Enable External DNS <code>bool</code> <code>true</code> no enable_external_secrets Enable External Secrets <code>bool</code> <code>true</code> no enable_fargate_fluentbit Enable Fargate Fluentbit <code>bool</code> <code>true</code> no enable_fluent_operator Enable fluent operator <code>bool</code> <code>true</code> no enable_grafana Enable Grafana <code>bool</code> <code>true</code> no enable_ingress_nginx Enable Ingress Nginx <code>bool</code> <code>false</code> no enable_karpenter Enable Karpenter <code>bool</code> <code>true</code> no enable_metrics_server Enable Metrics Server <code>bool</code> <code>true</code> no enable_okta Enable Okta integration <code>bool</code> <code>false</code> no enable_pagerduty Enable PagerDuty integration <code>bool</code> <code>false</code> no enable_prometheus_stack Enable Prometheus stack <code>bool</code> <code>true</code> no external_dns External DNS configurations <code>any</code> <code>{}</code> no external_secrets External Secrets configurations <code>any</code> <code>{}</code> no fargate_fluentbit Fargate Fluentbit configurations <code>any</code> <code>{}</code> no fluent_cloudwatch_retention_in_days Number of days to keep logs in cloudwatch <code>string</code> <code>\"7\"</code> no fluent_log_annotation Annotation to add to pods to get logs stored in cloudwatch <pre>object({    name  = optional(string, \"kaas.tamedia.ch/logging\")    value = optional(string, \"true\")  })</pre> <code>{}</code> no fluent_operator Fluent configurations <code>any</code> <code>{}</code> no grafana Grafana configurations, used to override default configurations <code>any</code> <code>{}</code> no ingress_nginx Ingress Nginx configurations <code>any</code> <code>{}</code> no karpenter Karpenter configurations <code>any</code> <code>{}</code> no metrics_server Metrics Server configurations <code>any</code> <code>{}</code> no name The name of the platform, a timestamp will be appended to this name to make the stack_name. If not provided, the name of the directory will be used. <code>string</code> <code>\"\"</code> no okta Okta configurations <pre>object({    base_url                    = optional(string, \"\")    secrets_manager_secret_name = optional(string, \"\")    kubernetes_secret_name      = optional(string, \"okta\")  })</pre> <code>{}</code> no pagerduty PagerDuty configurations <pre>object({    secrets_manager_secret_name = optional(string, \"\")    kubernetes_secret_name      = optional(string, \"pagerduty\")  })</pre> <code>{}</code> no prometheus_stack Prometheus stack configurations <code>any</code> <code>{}</code> no tags Default tags to apply to all resources <code>map(string)</code> <code>{}</code> no vpc Map of VPC configurations <code>any</code> <code>{}</code> no"},{"location":"#outputs","title":"Outputs","text":"Name Description eks Map of attributes for the EKS cluster network Map of attributes for the EKS cluster"},{"location":"#authors","title":"Authors","text":"<p>Module is maintained by Alfredo Gottardo, David Beauvererd, Davide Cammarata, Demetrio Carrara, Roland Bapst and Samuel Wibrow</p>"},{"location":"#license","title":"License","text":"<p>Apache 2 Licensed. See LICENSE for full details.</p>"},{"location":"examples/","title":"Examples","text":"<p>Common examples of how to use the module</p>"},{"location":"examples/#complete","title":"Complete","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/complete.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-complete\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { database = 26 },\n      { karpenter = 22 }\n    ]\n  }\n\n  # Optional addons\n  enable_downscaler = true\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/#simple","title":"Simple","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/simple.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-simple\"\n\n  vpc = {\n    enabled = true\n  }\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/#datadog","title":"Datadog","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/datadog.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    region               = \"eu-central-1\"\n    dynamodb_table       = \"terraform-lock\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    time = {\n      source  = \"hashicorp/time\"\n      version = \"0.11.2\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-datadog\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  karpenter = {\n    pod_annotations = {\n      \"ad.datadoghq.com/controller.checks\" = jsonencode(\n        {\n          \"karpenter\" : {\n            \"init_config\" : {},\n            \"instances\" : [{ \"openmetrics_endpoint\" : \"http://%%host%%:8000/metrics\" }]\n          }\n        }\n      )\n    }\n    memory_request = \"768Mi\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { database = 26 },\n      { karpenter = 22 }\n    ]\n  }\n}\n\nmodule \"datadog\" {\n  source = \"../../modules/datadog\"\n\n  cluster_name   = module.k8s_platform.eks.cluster_name\n  datadog_secret = \"dai/datadog/tamedia/keys\"\n  environment    = \"sandbox\"\n  product_name   = \"dai\"\n\n  depends_on = [module.k8s_platform]\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/#lacework","title":"Lacework","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/lacework.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    lacework = {\n      source  = \"lacework/lacework\"\n      version = \"~&gt; 1.8\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\ndata \"aws_secretsmanager_secret\" \"lacework\" {\n  name = \"dai/lacework/tamedia/apiKey\"\n}\n\ndata \"aws_secretsmanager_secret_version\" \"lacework\" {\n  secret_id = data.aws_secretsmanager_secret.lacework.id\n}\n\nprovider \"lacework\" {\n  account    = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"account\"]\n  subaccount = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"subAccount\"]\n  api_key    = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"keyId\"]\n  api_secret = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"secret\"]\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-lacework\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { karpenter = 22 }\n    ]\n  }\n}\n\nmodule \"lacework\" {\n  source = \"../../modules/lacework\"\n\n  cluster_name = module.k8s_platform.eks.cluster_name\n\n  agent_tags = {\n    KubernetesCluster = module.k8s_platform.eks.cluster_name\n  }\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"faq/","title":"FAQ","text":"<p>tba</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This getting started guide will help you deploy your first EKS cluster.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Ensure that you have installed the following tools locally:</p> <ul> <li>awscli</li> <li>kubectl</li> <li>terraform</li> </ul>"},{"location":"getting-started/#deploy","title":"Deploy","text":"<ol> <li> <p>For consuming EKS Blueprints, please see the Consumption section. For exploring and trying out the patterns provided, please clone the project locally to quickly get up and running with a pattern. After cloning the project locally, <code>cd</code> into the pattern directory of your choice.</p> </li> <li> <p>To provision the pattern, the typical steps of execution are as follows:</p> <pre><code>terraform init\nterraform apply -auto-approve\n</code></pre> <p>For patterns that deviate from this general flow, see the pattern's respective <code>README.md</code> for more details.</p> <p>Terraform targeted apply</p> <p>Please see the Terraform Caveats section for details on the use of targeted Terraform apply's</p> </li> <li> <p>Once all of the resources have successfully been provisioned, the following command can be used to update the <code>kubeconfig</code> on your local machine and allow you to interact with your EKS Cluster using <code>kubectl</code>.</p> <pre><code>aws eks --region &lt;REGION&gt; update-kubeconfig --name &lt;CLUSTER_NAME&gt; --alias &lt;CLUSTER_NAME&gt;\n</code></pre> <p>Pattern Terraform outputs</p> <p>Most examples will output the <code>aws eks update-kubeconfig ...</code> command as part of the Terraform apply output to simplify this process for users</p> <p>Private clusters</p> <p>Clusters that do not enable the clusters public endpoint will require users to access the cluster from within the VPC. For these patterns, a sample EC2 or other means are provided to demonstrate how to access those clusters privately</p> <p>and without exposing the public endpoint. Please see the respective pattern's <code>README.md</code> for more details.</p> </li> <li> <p>Once you have updated your <code>kubeconfig</code>, you can verify that you are able to interact with your cluster by running the following command:</p> <pre><code>kubectl get nodes\n</code></pre> <p>This should return a list of the node(s) running in the cluster created. If any errors are encountered, please re-trace the steps above and consult the pattern's <code>README.md</code> for more details on any additional/specific steps that may be required.</p> </li> </ol>"},{"location":"getting-started/#destroy","title":"Destroy","text":"<p>To teardown and remove the resources created in the pattern, the typical steps of execution are as follows:</p> <pre><code>terraform destroy -auto-approve\n</code></pre> <p>Resources created outside of Terraform</p> <p>Depending on the pattern, some resources may have been created that Terraform is not aware of that will cause issues when attempting to clean up the pattern. For example, Karpenter is responsible for creating additional EC2 instances to satisfy the pod scheduling requirements. These instances will not be cleaned up by Terraform and will need to be de-provisioned BEFORE attempting to <code>terraform destroy</code>. This is why it is important that the addons, or any resources provisioned onto the cluster are cleaned up first. Please see the respective pattern's <code>README.md</code> for more details.</p>"},{"location":"examples/complete/","title":"Complete","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/complete.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-complete\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { database = 26 },\n      { karpenter = 22 }\n    ]\n  }\n\n  # Optional addons\n  enable_downscaler = true\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/datadog/","title":"DataDog","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/datadog.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    region               = \"eu-central-1\"\n    dynamodb_table       = \"terraform-lock\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    time = {\n      source  = \"hashicorp/time\"\n      version = \"0.11.2\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-datadog\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  karpenter = {\n    pod_annotations = {\n      \"ad.datadoghq.com/controller.checks\" = jsonencode(\n        {\n          \"karpenter\" : {\n            \"init_config\" : {},\n            \"instances\" : [{ \"openmetrics_endpoint\" : \"http://%%host%%:8000/metrics\" }]\n          }\n        }\n      )\n    }\n    memory_request = \"768Mi\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { database = 26 },\n      { karpenter = 22 }\n    ]\n  }\n}\n\nmodule \"datadog\" {\n  source = \"../../modules/datadog\"\n\n  cluster_name   = module.k8s_platform.eks.cluster_name\n  datadog_secret = \"dai/datadog/tamedia/keys\"\n  environment    = \"sandbox\"\n  product_name   = \"dai\"\n\n  depends_on = [module.k8s_platform]\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/lacework/","title":"Lacework","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/lacework.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    lacework = {\n      source  = \"lacework/lacework\"\n      version = \"~&gt; 1.8\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\ndata \"aws_secretsmanager_secret\" \"lacework\" {\n  name = \"dai/lacework/tamedia/apiKey\"\n}\n\ndata \"aws_secretsmanager_secret_version\" \"lacework\" {\n  secret_id = data.aws_secretsmanager_secret.lacework.id\n}\n\nprovider \"lacework\" {\n  account    = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"account\"]\n  subaccount = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"subAccount\"]\n  api_key    = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"keyId\"]\n  api_secret = jsondecode(data.aws_secretsmanager_secret_version.lacework.secret_string)[\"secret\"]\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-lacework\"\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n\n  vpc = {\n    enabled = true\n    cidr    = \"10.0.0.0/16\"\n    max_az  = 3\n    subnet_configs = [\n      { public = 24 },\n      { private = 24 },\n      { intra = 26 },\n      { karpenter = 22 }\n    ]\n  }\n}\n\nmodule \"lacework\" {\n  source = \"../../modules/lacework\"\n\n  cluster_name = module.k8s_platform.eks.cluster_name\n\n  agent_tags = {\n    KubernetesCluster = module.k8s_platform.eks.cluster_name\n  }\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"},{"location":"examples/simple/","title":"Simple","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  backend \"s3\" {\n    bucket               = \"tf-state-911453050078\"\n    key                  = \"examples/simple.tfstate\"\n    workspace_key_prefix = \"terraform-aws-kubernetes-platform\"\n    dynamodb_table       = \"terraform-lock\"\n    region               = \"eu-central-1\"\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    helm = {\n      source  = \"hashicorp/helm\"\n      version = \"~&gt; 2.6\"\n    }\n    kubectl = {\n      source  = \"alekc/kubectl\"\n      version = \"~&gt; 2.0\"\n    }\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~&gt; 2.27\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = local.region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.k8s_platform.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n    }\n  }\n}\n\nprovider \"kubectl\" {\n  apply_retry_count      = 5\n  host                   = module.k8s_platform.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.k8s_platform.eks.cluster_certificate_authority_data)\n  load_config_file       = false\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    args        = [\"eks\", \"get-token\", \"--cluster-name\", module.k8s_platform.eks.cluster_name]\n  }\n}\n\nlocals {\n  region = \"eu-central-1\"\n}\n\nmodule \"k8s_platform\" {\n  source = \"../../\"\n\n  name = \"ex-simple\"\n\n  vpc = {\n    enabled = true\n  }\n\n  cluster_admins = {\n    cicd = {\n      role_name = \"cicd-iac\"\n    }\n  }\n\n  tags = {\n    Environment = \"sandbox\"\n    GithubRepo  = \"terraform-aws-kubernetes-platform\"\n    GithubOrg   = \"tx-pts-dai\"\n  }\n}\noutput \"eks\" {\n  description = \"eks module outputs\"\n  value       = module.k8s_platform.eks\n}\n\noutput \"vpc\" {\n  description = \"vpc module outputs\"\n  value       = module.k8s_platform.network\n}\n\noutput \"zconfigure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.k8s_platform.eks.cluster_name} --alias ${module.k8s_platform.eks.cluster_name}\"\n}\n</code></pre>"}]}